{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# BIRCH — Balanced Iterative Reducing and Clustering using Hierarchies\n",
    "\n",
    "---\n",
    "\n",
    "## 1) Concept Overview\n",
    "\n",
    "- **Goal (big picture):** build a compact **CF-tree** that summarizes massive datasets into many small **micro-clusters**, then (optionally) perform global clustering on those summaries.\n",
    "\n",
    "- **Key idea:** instead of clustering all raw points, BIRCH **ingests points incrementally**, **compresses** them into leaf entries, and keeps the leaf entries **tight** using a radius **threshold**.\n",
    "\n",
    "---\n",
    "\n",
    "## 2) Clustering Feature (CF) — the summary triple\n",
    "\n",
    "- **A CF entry stores**:\n",
    "\n",
    "  $$\n",
    "  (N,\\ LS,\\ SS)\n",
    "  $$\n",
    "\n",
    "  where \\(N\\) is count, \\(LS=\\sum x_i\\) is the linear sum, \\(SS=\\sum x_i^2\\) is the squared sum (all element-wise for vectors).\n",
    "\n",
    "- **From a CF entry**:\n",
    "\n",
    "  - **Centroid**:\n",
    "\n",
    "    $$\n",
    "    \\mu \\;=\\; \\frac{LS}{N}\n",
    "    $$\n",
    "\n",
    "  - **(Mean-square) radius** (dispersion):\n",
    "\n",
    "    $$\n",
    "    R \\;=\\; \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}\\lVert x_i-\\mu\\rVert^2}\n",
    "      \\;=\\; \\sqrt{\\frac{SS}{N} - \\left\\lVert\\frac{LS}{N}\\right\\rVert^2}\n",
    "    $$\n",
    "\n",
    "  - **Diameter** (optional, average pairwise distance):\n",
    "\n",
    "    $$\n",
    "    D \\;\\approx\\; \\sqrt{\\frac{2}{N(N-1)}\\sum_{i<j}\\lVert x_i - x_j\\rVert^2}\n",
    "    $$\n",
    "\n",
    "---\n",
    "\n",
    "## 3) CF-Tree (structure + insertion rule)\n",
    "\n",
    "- **Height-balanced tree** with internal nodes holding up to a **branching factor** of children; leaves hold **CF entries** (micro-clusters).\n",
    "\n",
    "- **Insertion (greedy, local):** for a new point \\(x\\), descend the tree by choosing the **closest** child (e.g., by centroid distance), and at the leaf:\n",
    "\n",
    "  - **Try to absorb** \\(x\\) into the nearest CF entry if its radius stays **within threshold**:\n",
    "\n",
    "    $$\n",
    "    R_{\\text{new}} \\;\\le\\; \\text{threshold}\n",
    "    $$\n",
    "\n",
    "  - Otherwise **create a new CF entry**; if the node overflows, **split** (like a B-tree split), and update parent CFs along the path.\n",
    "\n",
    "---\n",
    "\n",
    "## 4) Phases (conceptual pipeline)\n",
    "\n",
    "- **Phase 1 — Build:** one (or few) scans over data to construct the **CF-tree** under the current threshold.\n",
    "\n",
    "- **Phase 2 — (Optional) Condense:** rebuild/compact the tree to reduce leaf count (e.g., merge very similar leaves).\n",
    "\n",
    "- **Phase 3 — Global clustering:** cluster the **leaf centroids**:\n",
    "\n",
    "  $$\n",
    "  \\{\\mu_\\ell\\}_{\\text{leaves}} \\;\\;\\xrightarrow{\\ \\text{K-Means / Agglomerative / etc.}\\ }\\;\\; \\text{final clusters}\n",
    "  $$\n",
    "\n",
    "- **Phase 4 — (Optional) Refinement:** reassign original points to the final clusters, if desired.\n",
    "\n",
    "---\n",
    "\n",
    "## 5) Parameters (and what they *mean*)\n",
    "\n",
    "- **Threshold** (core hyperparameter, radius cap for leaf CFs):\n",
    "\n",
    "  $$\n",
    "  R_{\\text{leaf}} \\;\\le\\; \\text{threshold}\n",
    "  $$\n",
    "\n",
    "  Smaller → finer micro-clusters; larger → coarser summaries.\n",
    "\n",
    "- **Branching factor** (max children per node):\n",
    "\n",
    "  $$\n",
    "  B \\in \\mathbb{N},\\ \\text{controls node capacity and depth}\n",
    "  $$\n",
    "\n",
    "- **Final cluster count (optional):**\n",
    "\n",
    "  $$\n",
    "  n_{\\text{clusters}} \\in \\mathbb{N} \\quad (\\text{used in the global clustering phase})\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "## 6) Why not “just use the tree” as the final clustering?\n",
    "\n",
    "- The CF-tree is a **local, greedy compression** (good for speed/memory), **not** a globally optimized clustering.\n",
    "\n",
    "  - Two nearby leaves can be parts of **one semantic cluster** (need merging).\n",
    "  - Some leaves can be **micro-noise** or artifacts of insertion order.\n",
    "  - Therefore, a **global pass** on leaf centroids improves **cluster coherence**.\n",
    "\n",
    "- **Shortcut:** if you set\n",
    "\n",
    "  $$\n",
    "  n_{\\text{clusters}} \\;=\\; \\text{None}\n",
    "  $$\n",
    "\n",
    "  many libraries will **return the leaves** directly (fast, approximate result).\n",
    "\n",
    "---\n",
    "\n",
    "## 7) Threshold behavior (tuning intuition)\n",
    "\n",
    "- **Too small** threshold:\n",
    "\n",
    "  $$\n",
    "  \\text{many leaves} \\;\\Rightarrow\\; \\text{over-segmentation}\n",
    "  $$\n",
    "\n",
    "- **Too large** threshold:\n",
    "\n",
    "  $$\n",
    "  \\text{few leaves} \\;\\Rightarrow\\; \\text{under-segmentation}\n",
    "  $$\n",
    "\n",
    "- **Practical tip:** warm-up on a sample; estimate typical intra-cluster scale (e.g., std or NN distance) and set threshold to a comparable magnitude. Adjust until the **leaf count** and **leaf radii** look reasonable.\n",
    "\n",
    "---\n",
    "\n",
    "## 8) Strengths & caveats\n",
    "\n",
    "- **Strengths:**\n",
    "\n",
    "  $$\n",
    "  \\text{Streaming/large-scale friendly},\\quad\n",
    "  \\text{one-pass (or few-pass)},\\quad\n",
    "  \\text{compact memory via CFs}\n",
    "  $$\n",
    "\n",
    "- **Caveats:**\n",
    "\n",
    "  $$\n",
    "  \\text{spherical/convex bias},\\quad\n",
    "  \\text{sensitive to threshold},\\quad\n",
    "  \\text{less suited for highly variable densities or complex shapes}\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "## 9) Comparison — BIRCH vs K-Means / DBSCAN / HDBSCAN\n",
    "\n",
    "| Aspect | **K-Means** | **DBSCAN** | **HDBSCAN** | **BIRCH** |\n",
    "|:--|:--|:--|:--|:--|\n",
    "| Core notion | $$\\min \\sum \\lVert x_i - \\mu_{c_i}\\rVert^2$$ | Density at $$\\varepsilon$$ + $$k$$ | Stability across all $$\\varepsilon$$ | CF-tree summaries $$\\to$$ global clustering |\n",
    "| Parameters | $$k$$ | $$\\varepsilon,\\ k$$ | $$\\text{min\\_cluster\\_size},\\ k$$ | $$\\text{threshold},\\ B,\\ n_{\\text{clusters}}$$ |\n",
    "| Shapes | Convex/spherical | Arbitrary | Arbitrary | Mostly spherical (per leaf) |\n",
    "| Varying density | ❌ | ⚠️ (single $$\\varepsilon$$) | ✅ | ❌ (local radius cap) |\n",
    "| Noise handling | ❌ | ✅ | ✅ | ❗ (limited; depends on phase-3 method) |\n",
    "| Scale (n large) | ✅ | ✅ (moderate n) | ⚠️ | ✅✅ (designed for large n) |\n",
    "| Output | Flat labels | Flat + noise | Hierarchy + stability | Leaf summaries + (optional) flat labels |\n",
    "\n",
    "---\n",
    "\n",
    "## 10) When to use BIRCH\n",
    "\n",
    "- **Very large datasets** where a direct global clustering is too slow or memory-heavy.\n",
    "\n",
    "  $$\n",
    "  \\text{Raw data} \\;\\Rightarrow\\; \\text{CF-tree (thousands of leaves)} \\;\\Rightarrow\\; \\text{cluster leaves}\n",
    "  $$\n",
    "\n",
    "- **Pre-clustering step**: compress first, then refine with K-Means/Agglomerative.\n",
    "\n",
    "- **Spherical-ish clusters**, moderate dimensionality; for embeddings, consider **normalization** or **DR** before BIRCH.\n",
    "\n",
    "---\n",
    "\n",
    "## 11) Takeaways\n",
    "\n",
    "- BIRCH trades **global optimality** for **speed + memory** via a CF-tree.\n",
    "- The **threshold** is the key knob: it controls **granularity** of micro-clusters.\n",
    "- For best results, **cluster the leaf centroids** (global phase) to merge micro-clusters into coherent final groups.\n",
    "\n",
    "---\n"
   ],
   "id": "4f66ec5cd2f3f713"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b874a73fef1d49cb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
