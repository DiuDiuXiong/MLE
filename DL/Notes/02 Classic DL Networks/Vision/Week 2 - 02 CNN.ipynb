{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(torch.cuda.get_device_name(0))"
   ],
   "id": "b990d2835ccab771"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "print(os.getpid())"
   ],
   "id": "6bd1a9a125e159ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# DL W2_2 CNN: CIFAR-100 Redemption Project\n",
    "\n",
    "## 1. Project Overview\n",
    "Following our previous attempt to classify **CIFAR-100** using a Multi-Layer Perceptron (MLP), we observed significant limitations. The MLP failed to capture the spatial dependencies within the $32 \\times 32$ pixel grids, leading to a \"parameter explosion\" and poor generalization.\n",
    "\n",
    "In this project, we transition to **Convolutional Neural Networks (CNNs)** to leverage local receptive fields, weight sharing, and spatial hierarchies.\n",
    "\n",
    "## 2. The Dataset: CIFAR-100\n",
    "- **Scale:** 60,000 $32 \\times 32$ color images.\n",
    "- **Classes:** 100 classes grouped into 20 superclasses.\n",
    "- **Complexity:** Only 500 training images per class. This makes the dataset highly prone to overfitting, requiring robust regularization.\n",
    "\n",
    "## 3. Technical Strategy (The \"MLE Sandwich\")\n",
    "To ensure \"interview-immune\" implementation and better performance, we are adopting the following architectural best practices:\n",
    "\n",
    "### A. Architectural Design\n",
    "- **Convolutional Blocks:** We will use a modular approach: `Conv2d` -> `BatchNorm2d` -> `ReLU` -> `Dropout`.\n",
    "- **Global Average Pooling (GAP):** Replacing the heavy Flatten/Dense head with GAP to maintain a low parameter count and support input-size flexibility.\n",
    "- **Batch Normalization:** Implementing BN after convolutions to stabilize internal covariate shift and allow for higher learning rates.\n",
    "\n",
    "### B. Regularization & Optimization\n",
    "- **Data Augmentation:** Using `RandomHorizontalFlip` and `RandomCrop` to artificially increase the training sample diversity.\n",
    "- **Smarter Weight Init:** Using He (Kaiming) Initialization suited for ReLU activations.\n",
    "- **Dropout:** Strategically placed after activations to prevent co-adaptation of neurons.\n",
    "\n",
    "## 4. Objectives\n",
    "1.  **Surpass MLP Baseline:** Drastically improve upon the accuracy achieved in the MLP experiment.\n",
    "2.  **Implementation Proficiency:** Correctly implement the spatial dimensions math ($I, K, P, S$).\n",
    "3.  **Visualization:** (Post-training) Use Grad-CAM or Filter Visualization to interpret what the model has learned.\n",
    "\n",
    "---"
   ],
   "id": "6b66e65b40937422"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Part 0 Data Loader & Data Preparation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "train_data_path = \"/root/lanyun-fs/ds/cifar100/train-00000-of-00001.parquet\"\n",
    "test_data_path = \"/root/lanyun-fs/ds/cifar100/test-00000-of-00001.parquet\"\n",
    "train_data = pd.read_parquet(train_data_path, engine=\"pyarrow\")\n",
    "test_data = pd.read_parquet(test_data_path, engine=\"pyarrow\")"
   ],
   "id": "34071a9e241bfd29"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. CIFAR-100 Normalization Constants\n",
    "CIFAR_MEAN = (0.5071, 0.4867, 0.4408)\n",
    "CIFAR_STD = (0.2675, 0.2565, 0.2761)\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2. VRAM-Resident Dataset Class\n",
    "class Cifar100VramDataset(Dataset):\n",
    "    \"\"\"\n",
    "    SRE Optimized: Pre-decodes images and stores the entire dataset in GPU VRAM\n",
    "    to eliminate PCIe and CPU bottlenecks.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, device, transform=None):\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Pre-calc normalization on CPU during initialization\n",
    "        normalize = T.Normalize(mean=CIFAR_MEAN, std=CIFAR_STD)\n",
    "\n",
    "        for idx in tqdm(range(len(df)), desc=\"Loading CIFAR to VRAM\"):\n",
    "            # Decode raw bytes\n",
    "            bytes_tensor = torch.frombuffer(df.iloc[idx][\"img\"][\"bytes\"], dtype=torch.uint8)\n",
    "            image = torchvision.io.decode_image(bytes_tensor, mode='RGB')\n",
    "\n",
    "            # Normalize and store as float32\n",
    "            normalized_img = normalize(image.float() / 255.0)\n",
    "            self.images.append(normalized_img)\n",
    "            self.labels.append(df.iloc[idx][\"fine_label\"])\n",
    "\n",
    "        # Stack into single 4D tensors and move to GPU once\n",
    "        self.images = torch.stack(self.images).to(device)\n",
    "        self.labels = torch.tensor(self.labels, dtype=torch.long).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # GPU-based augmentation applied here\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "# 3. GPU-Accelerated Augmentation (nn.Sequential)\n",
    "# This runs on the 4090 kernels during the DataLoader loop\n",
    "train_gpu_transforms = nn.Sequential(\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomCrop(32, padding=4),\n",
    ").to(DEVICE)\n",
    "\n",
    "# 4. Initialization\n",
    "print(f\"Initializing Datasets on {DEVICE}...\")\n",
    "\n",
    "# Training set gets the augmentation pipeline\n",
    "train_set = Cifar100VramDataset(train_data, device=DEVICE, transform=train_gpu_transforms)\n",
    "\n",
    "# Test set remains clean (transform=None)\n",
    "test_set = Cifar100VramDataset(test_data, device=DEVICE, transform=None)\n",
    "\n",
    "# 5. DataLoaders\n",
    "# Note: num_workers=0 is REQUIRED for VRAM-resident tensors to prevent CUDA re-init errors\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# Verification\n",
    "imgs, lbls = next(iter(train_loader))\n",
    "print(f\"\\nBatch successfully loaded to {imgs.device}\")\n",
    "print(f\"Batch Shape: {imgs.shape}\")\n",
    "print(f\"Label Shape: {lbls.shape}\")"
   ],
   "id": "cc4791301480e925"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Model Design Philosophy: The \"Redemption\" CNN\n",
    "\n",
    "Designing a CNN for CIFAR-100 requires a balance between **Feature Extraction** (spatial depth) and **Model Capacity** (channel depth). Below are the design principles adopted for this architecture.\n",
    "\n",
    "### 2.1 The \"Rule of Two\": Stacking Convolutions\n",
    "Instead of a single Convolution followed immediately by Pooling, we use **Double-Convolution Blocks** (e.g., $Conv \\to Conv \\to Pool$).\n",
    "* **Effective Receptive Field (ERF):** Stacking two $3\\times3$ kernels gives the model a $5\\times5$ view of the image but with fewer parameters and more non-linearity (two ReLU activations instead of one).\n",
    "* **Information Preservation:** We allow the model to extract more complex features at a specific resolution before downsampling the spatial data.\n",
    "\n",
    "### 2.2 The Channel-Spatial Trade-off\n",
    "As we progress deeper into the network, we apply the **Double-Half Rule**:\n",
    "* **The Action:** We use `MaxPool` to halve the spatial resolution ($32 \\to 16 \\to 8 \\to 4$).\n",
    "* **The Compensation:** To prevent information loss, we **double the number of channels** ($64 \\to 128 \\to 256$).\n",
    "* **The Logic:** We sacrifice \"where\" something is (spatial precision) to gain \"what\" something is (semantic depth). While pooling removes 75% of spatial data points, doubling channels provides more \"bins\" to store high-level concepts.\n",
    "\n",
    "\n",
    "\n",
    "### 2.3 Graduated Regularization (Dropout Strategy)\n",
    "We avoid a \"one-size-fits-all\" Dropout rate. Instead, we use a **Graduated Dropout** approach:\n",
    "* **Early Layers (0.1 - 0.2):** Low dropout to preserve the raw features (edges/colors) needed by deeper layers.\n",
    "* **Deep Layers (0.3 - 0.4):** Higher dropout to prevent the model from memorizing specific complex patterns (overfitting) in the small CIFAR-100 training set.\n",
    "* **The Head (0.5):** Maximum dropout at the classification stage to ensure robust reasoning.\n",
    "\n",
    "### 2.4 The Classification Head: Flattening vs. GAP\n",
    "For CIFAR-100, we choose a **Flattening Head** over Global Average Pooling (GAP).\n",
    "* **Why?** GAP is highly efficient but can be too restrictive for 100 classes. By flattening to a $4 \\times 4 \\times 256$ vector and passing it through a dense hidden layer ($4096 \\to 512$), we give the model more \"reasoning neurons\" to distinguish between subtle class differences (e.g., different types of trees or insects).\n",
    "\n",
    "\n",
    "\n",
    "### 2.5 SRE Optimization: Parameter Efficiency\n",
    "* **Bias=False:** We disable bias in `Conv2d` and `Linear` layers followed immediately by `BatchNorm`. Since BN centers the data by subtracting the mean, a learned bias term is mathematically redundant.\n",
    "* **Inplace Activation:** Using `ReLU(inplace=True)` to reduce memory allocation on the 4090."
   ],
   "id": "63fc971ff9a7cefb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "CIFAR_MEAN = (0.5071, 0.4867, 0.4408)\n",
    "CIFAR_STD = (0.2675, 0.2565, 0.2761)\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "class CifarRedemptionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CifarRedemptionModel, self).__init__()\n",
    "\n",
    "        # --- Block 1: 32x32 -> 16x16 ---\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # Halves to 16x16\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "        # --- Block 2: 16x16 -> 8x8 ---\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # Halves to 8x8\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        # --- Block 3: 8x8 -> 4x4 ---\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # Halves to 4x4\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        # --- Head: 4*4*256 = 4096 ---\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc_section = nn.Sequential(\n",
    "            nn.Linear(4096, 512, bias=False),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 100) # 100 classes for CIFAR-100\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc_section(x)\n",
    "        return x\n",
    "\n",
    "# SRE Initialization\n",
    "model = CifarRedemptionModel().to(DEVICE)\n",
    "print(model)"
   ],
   "id": "43f531e81f7329c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.eval()\n",
    "dummy_input = torch.randn(1,3,32,32)\n",
    "dummy_input = dummy_input.to(DEVICE)\n",
    "output = model(dummy_input)\n",
    "print(output.shape)\n",
    "model.train()"
   ],
   "id": "32bfa4d8b07c65c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- Training Setup ---\n",
    "epochs = 50\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# OneCycleLR: steps_per_epoch must match the number of BATCHES (len(train_loader))\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer=optimiser,\n",
    "    max_lr=0.01,\n",
    "    steps_per_epoch=len(train_loader), # len(loader) = total batches (~49)\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "# --- Training Loop ---\n",
    "for epoch in range(epochs):\n",
    "    model.train() # Set to TRAIN mode (enables Dropout & Batch Norm updates)\n",
    "\n",
    "    train_correct = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        # 1. Reset Gradients: Must be INSIDE the batch loop to prevent accumulation\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # 2. Forward Pass: Images are already on GPU from our VRAM Dataset\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 3. Backward Pass & Step\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        scheduler.step() # OneCycleLR updates LR after every batch\n",
    "\n",
    "        # 4. Accuracy Math: Convert GPU sum to Python int via .item()\n",
    "        # This prevents a \"memory leak\" of tensors in your RAM/VRAM\n",
    "        batch_correct = (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "        train_correct += batch_correct\n",
    "\n",
    "    # --- Evaluation Phase ---\n",
    "    model.eval() # Set to EVAL mode (disables Dropout, uses fixed BN stats)\n",
    "    test_correct = 0\n",
    "\n",
    "    with torch.no_grad(): # Disable gradient calculation to save VRAM/Compute\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            # Accumulate correct predictions for the whole test set\n",
    "            test_correct += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "\n",
    "    # --- Performance Reporting ---\n",
    "    # We divide by len(dataset) to get true percentage, NOT len(loader)\n",
    "    train_acc = (train_correct / len(train_set)) * 100\n",
    "    test_acc = (test_correct / len(test_set)) * 100\n",
    "\n",
    "    print(f\"Epoch {epoch+1:02d} | Train Acc: {train_acc:.2f}% | Test Acc: {test_acc:.2f}%\")"
   ],
   "id": "2c8b1452b354ba5e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Runtime Evaluation",
   "id": "4a8520cc6871429c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "601d743b52423ed9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![image.png](attachment:610ca402-df30-47fd-8466-0828104cc1e0.png)",
   "id": "b1a0c04bb7fd07d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch.profiler\n",
    "import os\n",
    "\n",
    "# Ensure DEVICE is defined for your 4090\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1. Setup a fresh model\n",
    "profiling_model = CifarRedemptionModel().to(DEVICE)\n",
    "profiling_optim = torch.optim.Adam(profiling_model.parameters(), lr=0.001)\n",
    "profiling_sched = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    profiling_optim, max_lr=0.01, steps_per_epoch=len(train_loader), epochs=1\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "log_dir = './log/high_confidence_profile'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "def run_extended_profile(model, train_loader, test_loader):\n",
    "    # Change GPU to CUDA here\n",
    "    with torch.profiler.profile(\n",
    "        activities=[\n",
    "            torch.profiler.ProfilerActivity.CPU,\n",
    "            torch.profiler.ProfilerActivity.CUDA, # <--- Corrected attribute\n",
    "        ],\n",
    "        schedule=torch.profiler.schedule(wait=2, warmup=5, active=15, repeat=1),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler(log_dir),\n",
    "        record_shapes=True,\n",
    "        with_stack=True\n",
    "    ) as prof:\n",
    "\n",
    "        # --- PHASE A: Profile Training ---\n",
    "        model.train()\n",
    "        print(\"Profiling Training...\")\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            profiling_optim.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            profiling_optim.step()\n",
    "            profiling_sched.step()\n",
    "\n",
    "            prof.step()\n",
    "            if i >= 25: break\n",
    "\n",
    "        # --- PHASE B: Profile Validation ---\n",
    "        model.eval()\n",
    "        print(\"Profiling Validation...\")\n",
    "        with torch.no_grad():\n",
    "            for i, (images, labels) in enumerate(test_loader):\n",
    "                outputs = model(images)\n",
    "                _ = (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "\n",
    "                prof.step()\n",
    "                if i >= 10: break\n",
    "\n",
    "    print(f\"High-confidence trace saved to {log_dir}\")\n",
    "    print(\"--- Top 10 CPU Bottlenecks (Total Time) ---\")\n",
    "    # 'cpu_time_total' includes time spent in children functions\n",
    "    print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "\n",
    "    print(\"\\n--- Top 10 CPU Bottlenecks (Self Time) ---\")\n",
    "    # 'self_cpu_time_total' is time spent ONLY in that specific function (ignores children)\n",
    "    # This is the best way to find the actual line of code causing the stall.\n",
    "    print(prof.key_averages().table(sort_by=\"self_cpu_time_total\", row_limit=10))\n",
    "\n",
    "    print(\"\\n--- Top 10 GPU (CUDA) Kernels ---\")\n",
    "    print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
    "\n",
    "# Execute\n",
    "run_extended_profile(profiling_model, train_loader, test_loader)"
   ],
   "id": "2438b3dfd9c132cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### RCA: CPU Bottleneck in GPU Training Pipeline\n",
    "**Observation:** Telemetry showed 100% CPU utilization and ~40% GPU \"sawtooth\" utilization.\n",
    "**Profiler Discovery:** 1. `enumerate(DataLoader)` consumed ~46% of CPU time.\n",
    "2. `aten::pad` and `aten::flip` (Augmentations) appeared as high \"Self CPU\" costs.\n",
    "**Root Cause:** Even though the augmentation block was on the GPU, calling it inside `__getitem__` forced the 4090 to process 1,024 images sequentially. This created massive Python overhead and \"Context Switching\" costs for every single image.\n",
    "**Fix:** Move the augmentation pipeline out of the `Dataset` and into the training loop to perform **Batch-Level Augmentation**. This allows the 4090 to process all 1,024 images in parallel with a single CUDA kernel launch."
   ],
   "id": "3e658ab68f654e48"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Cifar100VramDataset(Dataset):\n",
    "    def __init__(self, df, device):\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        normalize = T.Normalize(mean=CIFAR_MEAN, std=CIFAR_STD)\n",
    "\n",
    "        for idx in tqdm(range(len(df)), desc=\"Loading CIFAR to VRAM\"):\n",
    "            bytes_tensor = torch.frombuffer(df.iloc[idx][\"img\"][\"bytes\"], dtype=torch.uint8)\n",
    "            image = torchvision.io.decode_image(bytes_tensor, mode='RGB')\n",
    "            # Pre-calculate normalization on CPU\n",
    "            normalized_img = normalize(image.float() / 255.0)\n",
    "            self.images.append(normalized_img)\n",
    "            self.labels.append(df.iloc[idx][\"fine_label\"])\n",
    "\n",
    "        # Move to GPU once\n",
    "        self.images = torch.stack(self.images).to(device)\n",
    "        self.labels = torch.tensor(self.labels, dtype=torch.long).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # NO transformation here. Just returning the VRAM-resident tensors.\n",
    "        return self.images[idx], self.labels[idx]"
   ],
   "id": "de85b5dd0e823538"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "### RCA: DataLoader Bottleneck (enumerate)\n",
    "**Observation:** `enumerate(DataLoader)` consumed ~46.6% of CPU time.\n",
    "**Root Cause:** The standard DataLoader iterator has high Python overhead when processing\n",
    "very small images (32x32) on a high-speed card like the 4090.\n",
    "**Fix:** Skip the DataLoader. Use direct GPU-tensor slicing to feed the model.\n",
    "\"\"\"\n",
    "import time\n",
    "\n",
    "def train_with_direct_slicing(model, train_set, test_set, epochs=50, batch_size=1024):\n",
    "    model.to(DEVICE)\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Calculate steps for OneCycleLR\n",
    "    steps_per_epoch = (len(train_set) + batch_size - 1) // batch_size\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimiser, max_lr=0.01, steps_per_epoch=steps_per_epoch, epochs=epochs\n",
    "    )\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Access raw tensors from your VramDataset\n",
    "    train_imgs = train_set.images\n",
    "    train_lbls = train_set.labels\n",
    "    test_imgs = test_set.images\n",
    "    test_lbls = test_set.labels\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        train_correct = 0\n",
    "\n",
    "        # 1. Shuffle indices on GPU to avoid CPU interaction\n",
    "        indices = torch.randperm(len(train_set), device=DEVICE)\n",
    "\n",
    "        # 2. Direct Slicing Loop (No enumerate/DataLoader)\n",
    "        for i in range(0, len(train_set), batch_size):\n",
    "            batch_idx = indices[i : i + batch_size]\n",
    "\n",
    "            # Direct VRAM slice - extremely fast on 4090\n",
    "            images = train_imgs[batch_idx]\n",
    "            labels = train_lbls[batch_idx]\n",
    "\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            # Apply batch-level GPU transforms\n",
    "            images = train_gpu_transforms(images)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            train_correct += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "\n",
    "        # --- Fast Evaluation ---\n",
    "        model.eval()\n",
    "        test_correct = 0\n",
    "        with torch.no_grad():\n",
    "            # Slice test set directly (no shuffle needed)\n",
    "            for i in range(0, len(test_set), batch_size):\n",
    "                images = test_imgs[i : i + batch_size]\n",
    "                labels = test_lbls[i : i + batch_size]\n",
    "                outputs = model(images)\n",
    "                test_correct += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"Epoch {epoch+1:02d} | Time: {epoch_time:.2f}s | \"\n",
    "              f\"Train Acc: {(train_correct/len(train_set))*100:.2f}% | \"\n",
    "              f\"Test Acc: {(test_correct/len(test_set))*100:.2f}%\")\n",
    "\n",
    "# Execute the \"Zero-Overhead\" run\n",
    "model = CifarRedemptionModel()\n",
    "train_with_direct_slicing(model, train_set, test_set)"
   ],
   "id": "51835f4f384cd936"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![image.png](attachment:a8dfcf1b-ae77-443e-863f-3251bce6ee7f.png)",
   "id": "cc78362de80ca27a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. RCA & Optimization: Breaking the 4090 Bottleneck\n",
    "\n",
    "> **SRE Performance Deep-Dive**\n",
    "> **Hardware:** NVIDIA RTX 4090 (24GB VRAM)\n",
    "> **Target:** Eliminate 100% CPU pinning and \"starving\" GPU.\n",
    "\n",
    "---\n",
    "\n",
    "### 5.1 The \"Python Tax\" & Kernel Launch Overhead\n",
    "* **Observation:** Telemetry showed 100% CPU utilization while the GPU exhibited a \"sawtooth\" pattern (frequent drops in utilization).\n",
    "* **Root Cause:** Standard `DataLoader` logic and `__getitem__` transformations are executed sequentially in the Python interpreter.\n",
    "* **The Dispatch Problem:** Every time the CPU instructs the GPU to perform a transform (e.g., `flip`, `pad`) on a **single** image, it incurs a \"Kernel Launch\" overhead. On a 4090, the time for the CPU to send the command across the PCIe bus often exceeded the time taken for the GPU to execute the work on a $32 \\times 32$ image.\n",
    "* **Resolution:** Move transforms to the **Batch Level** (after images are grouped into a 4D tensor). This allows the CPU to send **one command** for 1,024 images, maximizing GPU occupancy and parallelization.\n",
    "\n",
    "### 5.2 The `enumerate(DataLoader)` Bottleneck\n",
    "* **Observation:** Profiling showed nearly **46.6%** of CPU time consumed within the `DataLoader` iterator logic (`SingleProcessDataLoaderIter`).\n",
    "* **Root Cause:** The `DataLoader` is a complex Python state machine designed for flexibility (handling diverse file formats, shuffling, etc.), which introduces significant per-item overhead when processing small images at high speeds.\n",
    "* **Resolution:** For datasets fitting entirely in VRAM, **Direct Tensor Slicing** (using `torch.randperm` for GPU-based shuffling) bypasses the Python iterator tax entirely, yielding near-instantaneous batch retrieval.\n",
    "\n",
    "---\n",
    "\n",
    "### 5.3 Scaling to Large Datasets (H100/100GB+ Scale)\n",
    "While direct slicing works for CIFAR-100, larger-than-RAM datasets require a \"middle ground\" to maintain speed:\n",
    "1. **Batch Sampling:** Use a `BatchSampler` to tell the `DataLoader` to fetch a list of 1,024 indices at once, enabling a single high-speed slice in `__getitem__`.\n",
    "2. **Chunked Loading:** Use formats like **Parquet** or **WebDataset** to load \"shards\" of data (e.g., 1,000 images) into a buffer, move the buffer to GPU, and slice within that GPU-resident block."
   ],
   "id": "5a8d966b4b0d6a35"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torch.utils.data import DataLoader, BatchSampler, RandomSampler, SequentialSampler\n",
    "\n",
    "class CifarBatchOptimizedDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        # Data is already on the 4090 VRAM\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        By using a BatchSampler, 'idx' will be a list of 1024 integers.\n",
    "        This allows one single VRAM slice instead of 1024 individual ones.\n",
    "        \"\"\"\n",
    "        return self.images[idx], self.labels[idx]\n",
    "\n",
    "# 1. Initialize our optimized Dataset\n",
    "train_set_opt = CifarBatchOptimizedDataset(train_set.images, train_set.labels)\n",
    "test_set_opt = CifarBatchOptimizedDataset(test_set.images, test_set.labels)\n",
    "\n",
    "# 2. Setup the BatchSamplers\n",
    "# This is the \"brain\" that yields a list of indices [0, 1, 2...1023] at once\n",
    "train_batch_sampler = BatchSampler(\n",
    "    RandomSampler(train_set_opt),\n",
    "    batch_size=1024,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "test_batch_sampler = BatchSampler(\n",
    "    SequentialSampler(test_set_opt),\n",
    "    batch_size=1024,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "# 3. Setup DataLoaders\n",
    "# IMPORTANT: Do NOT set batch_size here; the sampler already defines it.\n",
    "# We set num_workers=0 because the data is already in VRAM.\n",
    "train_loader = DataLoader(train_set_opt, batch_sampler=train_batch_sampler)\n",
    "test_loader = DataLoader(test_set_opt, batch_sampler=test_batch_sampler)\n",
    "\n",
    "# 4. Optimized Training Loop\n",
    "def train_with_batch_loader(model, train_loader, test_loader, epochs=50):\n",
    "    model.to(DEVICE)\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimiser, max_lr=0.01, steps_per_epoch=len(train_loader), epochs=epochs\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        train_correct = 0\n",
    "\n",
    "        # Now 'enumerate' only triggers ONCE per batch, not once per image.\n",
    "        # This drastically reduces Python overhead.\n",
    "        for images, labels in train_loader:\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            # Still apply batch-level transforms for 4090 efficiency\n",
    "            images = train_gpu_transforms(images)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            train_correct += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        test_correct = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                outputs = model(images)\n",
    "                test_correct += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"Epoch {epoch+1:02d} | Time: {epoch_time:.2f}s | \"\n",
    "              f\"Train Acc: {(train_correct/len(train_set_opt))*100:.2f}% | Test Acc: {(test_correct/len(test_set))*100:.2f}%\")\n",
    "\n",
    "# Execute\n",
    "model = CifarRedemptionModel()\n",
    "train_with_batch_loader(model, train_loader, test_loader)"
   ],
   "id": "a6a1f67f83f5171b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch.profiler\n",
    "import os\n",
    "import time\n",
    "\n",
    "# 1. Reset Model and Optimizer\n",
    "profiling_model = CifarRedemptionModel().to(DEVICE)\n",
    "profiling_optim = torch.optim.Adam(profiling_model.parameters(), lr=0.001)\n",
    "profiling_sched = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    profiling_optim, max_lr=0.01, steps_per_epoch=len(train_loader), epochs=10\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "log_dir = './log/batchsampler_high_conf'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "def run_batchsampler_high_conf(model, train_loader, test_loader, epochs=10):\n",
    "    # schedule: wait 2, warmup 1, active 10.\n",
    "    # This ensures we get a solid sample of the BatchSampler's steady state.\n",
    "    with torch.profiler.profile(\n",
    "        activities=[\n",
    "            torch.profiler.ProfilerActivity.CPU,\n",
    "            torch.profiler.ProfilerActivity.CUDA,\n",
    "        ],\n",
    "        schedule=torch.profiler.schedule(wait=2, warmup=1, active=10, repeat=1),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler(log_dir),\n",
    "        record_shapes=True,\n",
    "        with_stack=True\n",
    "    ) as prof:\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            start_time = time.time()\n",
    "            model.train()\n",
    "\n",
    "            for i, (images, labels) in enumerate(train_loader):\n",
    "                profiling_optim.zero_grad()\n",
    "\n",
    "                # GPU Batch Augmentation\n",
    "                images = train_gpu_transforms(images)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                profiling_optim.step()\n",
    "                profiling_sched.step()\n",
    "\n",
    "                # Signals profiler to transition phases\n",
    "                prof.step()\n",
    "\n",
    "                # We only need enough steps to satisfy the 'active=10' requirement\n",
    "                if epoch == 0 and i >= 15: break\n",
    "\n",
    "            # Fast Evaluation (not profiled, prof.step is only inside training loop)\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for images, labels in test_loader:\n",
    "                    _ = model(images)\n",
    "\n",
    "            print(f\"Epoch {epoch+1:02d} | Time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "    # Final Profiler Report (This will take a moment to compute)\n",
    "    print(\"\\n--- High Confidence: BatchSampler Self CPU ---\")\n",
    "    print(prof.key_averages().table(sort_by=\"self_cpu_time_total\", row_limit=15))\n",
    "\n",
    "# Execute\n",
    "run_batchsampler_high_conf(profiling_model, train_loader, test_loader)"
   ],
   "id": "33e3e5eeb43e30ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torch.utils.data import DataLoader, BatchSampler, RandomSampler, SequentialSampler\n",
    "\n",
    "class CifarBatchOptimizedDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        # Data is already on VRAM\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, indices):\n",
    "        \"\"\"\n",
    "        By setting batch_size=None in DataLoader, 'indices' arrives here\n",
    "        as the full list/tensor of 1024 integers.\n",
    "        We perform a single GPU-to-GPU memory slice.\n",
    "        \"\"\"\n",
    "        # Because images/labels are already on GPU, this is a vectorized gather\n",
    "        return self.images[indices], self.labels[indices]\n",
    "\n",
    "# 1. Initialize\n",
    "train_set_opt = CifarBatchOptimizedDataset(train_set.images, train_set.labels)\n",
    "test_set_opt = CifarBatchOptimizedDataset(test_set.images, test_set.labels)\n",
    "\n",
    "# 2. Setup the BatchSamplers (Same as before)\n",
    "train_batch_sampler = BatchSampler(\n",
    "    RandomSampler(train_set_opt),\n",
    "    batch_size=1024,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "test_batch_sampler = BatchSampler(\n",
    "    SequentialSampler(test_set_opt),\n",
    "    batch_size=1024,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "# 3. Setup DataLoaders (THE ADJUSTMENT)\n",
    "# Note: We pass train_batch_sampler to 'sampler' and set batch_size=None.\n",
    "# This tells DataLoader: \"Take whatever the sampler yields and pass it DIRECTLY\n",
    "# to __getitem__ without looping or collating.\"\n",
    "train_loader = DataLoader(\n",
    "    train_set_opt,\n",
    "    sampler=train_batch_sampler,\n",
    "    batch_size=None,  # This is the \"magic\" switch for vectorization\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_set_opt,\n",
    "    sampler=test_batch_sampler,\n",
    "    batch_size=None,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# 4. Optimized Training Loop\n",
    "def train_with_batch_loader(model, train_loader, test_loader, epochs=50):\n",
    "    model.to(DEVICE)\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimiser, max_lr=0.01, steps_per_epoch=len(train_loader), epochs=epochs\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        train_correct = 0\n",
    "\n",
    "        # Now 'enumerate' only triggers ONCE per batch, not once per image.\n",
    "        # This drastically reduces Python overhead.\n",
    "        for images, labels in train_loader:\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            # Still apply batch-level transforms for 4090 efficiency\n",
    "            images = train_gpu_transforms(images)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            train_correct += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        test_correct = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                outputs = model(images)\n",
    "                test_correct += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"Epoch {epoch+1:02d} | Time: {epoch_time:.2f}s | \"\n",
    "              f\"Train Acc: {(train_correct/len(train_set_opt))*100:.2f}% | Test Acc: {(test_correct/len(test_set))*100:.2f}%\")\n",
    "\n",
    "# Execute\n",
    "model = CifarRedemptionModel()\n",
    "train_with_batch_loader(model, train_loader, test_loader)"
   ],
   "id": "adfc6435c067571f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. SRE Deep-Dive: The \"Generalization Tax\" of DataLoaders\n",
    "\n",
    "### 6.1 The Performance Gap\n",
    "| Strategy | Epoch Time | Performance Delta | SRE Status |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Direct Slicing** (Manual) | **1.99s** | Baseline | Theoretical Limit |\n",
    "| **Vectorized Fetching** (`batch_size=None`) | **2.00s** | ~0.5% Overhead | **Optimized** |\n",
    "| **Standard BatchSampler** | **2.30s** | ~15% Overhead | **Sub-optimal** |\n",
    "| **Naive DataLoader** (`batch_size=1024`) | **>5.00s** | >150% Overhead | **Bottlenecked** |\n",
    "\n",
    "### 6.2 RCA: Why is `BatchSampler` faster than the Naive method?\n",
    "Even though the `DataLoader` still iterates through the indices under the hood in this version, we see a massive speedup (2.3s vs 5s+) due to two main factors:\n",
    "\n",
    "1.  **Reduced Iterator Dispatch:** In the naive version, the `DataLoader` calls the `Sampler` 1,024 separate times *per batch*. With `BatchSampler`, it makes **one** call to get the entire list. In Python, reducing ~20,000 function calls per epoch significantly lowers the CPU dispatch latency.\n",
    "2.  **Simplified Internal State (The \"Counting\" Tax):** * In the **Naive** version, the `DataLoader` must maintain a counter, an internal list, and a loop to \"fill the bucket\" 1,024 times before it can proceed.\n",
    "    * With a **BatchSampler**, the `DataLoader` receives a pre-filled \"bucket\" of indices in a single step. It skips the internal \"collecting\" logic and hands the list directly to the fetcher, reducing the administrative overhead at the Python/C++ boundary.\n",
    "\n",
    "### 6.3 The Remaining Bottleneck: `aten::select`\n",
    "Looking at the `torch.profiler` trace for this `BatchSampler` version:\n",
    "* **Call Density:** `aten::select` is still called **20,480 times**.\n",
    "* **RCA:** Even though the *sampling* is now fast, the *fetching* is still \"chatty.\" The `MapDataFetcher` is still looping through that list of 1024 indices and calling `dataset[idx]` individually. On a 4090, these thousands of tiny C++/CUDA kernel launches create a \"scheduling bottleneck\" where the GPU spends time waiting for the next small instruction.\n",
    "\n",
    "### 6.4 Level 2 Optimization: Vectorized Fetching (`batch_size=None`)\n",
    "To close the final 15% gap, we move to **Vectorized Fetching**. By setting `batch_size=None` and using the `BatchSampler` as our primary `sampler`, we change the data flow topology:\n",
    "\n",
    "* **The Logic:** We tell PyTorch: \"Don't loop. Take this list of 1,024 indices and pass it directly to the Dataset's `__getitem__` as a single object.\"\n",
    "* **The Result:** Those 20,480 calls to `aten::select` are replaced by **one single gather operation** per batch. This allows the 4090's memory bus to pull all 1,024 images at once, hitting our near-limit of **2.0s**.\n",
    "\n",
    "### 6.5 SRE Verdict: Choosing the Strategy\n",
    "* **Use Direct Slicing:** For static datasets fitting entirely in VRAM (best for rapid local prototyping).\n",
    "* **Use Vectorized DataLoader (`batch_size=None`):** When you need full framework features (Shuffling, Distributed Training) with \"Line-Rate\" 4090 throughput.\n",
    "* **Use Standard DataLoader:** Only when individual item processing (like complex CPU-based augmentation) is so slow that it dwarfs the orchestration tax.\n",
    "\n",
    "> **Reminders for Large Datasets:** When data exceeds VRAM, the Vectorized approach remains king. Using it with **Parquet/Arrow** allows you to perform \"Row Group\" reads, which is significantly faster than row-by-row disk I/O."
   ],
   "id": "88b3b19fb3eec5a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Internal Layer Visualisation",
   "id": "589bb3cb2d18d9e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(model)",
   "id": "8f462a436ae96afd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "STRATEGY 1: Feature Map Visualization (Activations)\n",
    "WHAT: Intercepts the data stream as it flows through your specific 'block' architecture.\n",
    "VALUE: Observe 'Feature Extraction'. Block 1 should show sharp outlines; Block 3 should show abstract blobs.\n",
    "\n",
    "STRATEGY 2: Filter (Weight) Visualization\n",
    "WHAT: Extracts the 3x3 weight kernels from the very first Conv2d layer.\n",
    "VALUE: Observe 'Model Eyes'. Healthy models show oriented lines/edges and color gradients.\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def run_internal_visualizations(model, sample_img):\n",
    "    model.eval()\n",
    "\n",
    "    # --- STRATEGY 2: Filter (Weight) Visualization ---\n",
    "    print(\"Executing Strategy 2: Visualizing First Layer Filters...\")\n",
    "    # Access Block 1 -> Layer 0 (The first Conv2d)\n",
    "    first_conv = model.block1[0]\n",
    "    weights = first_conv.weight.data.cpu()\n",
    "\n",
    "    # Normalize weights to [0, 1] for visibility\n",
    "    w_min, w_max = weights.min(), weights.max()\n",
    "    weights_norm = (weights - w_min) / (w_max - w_min)\n",
    "\n",
    "    fig2, axes2 = plt.subplots(8, 8, figsize=(10, 10))\n",
    "    for i, ax in enumerate(axes2.flat):\n",
    "        if i < 64:\n",
    "            # Permute (C, H, W) -> (H, W, C) for Matplotlib\n",
    "            filter_img = weights_norm[i].permute(1, 2, 0).numpy()\n",
    "            ax.imshow(filter_img, interpolation='nearest')\n",
    "            ax.axis('off')\n",
    "    plt.suptitle(\"Strategy 2: First Layer Weights (The 64 'Eyes')\", fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "    # --- STRATEGY 1: Feature Map Visualization ---\n",
    "    print(\"\\nExecuting Strategy 1: Visualizing Feature Map Activations...\")\n",
    "    # Ensure input is [1, 3, 32, 32]\n",
    "    if sample_img.dim() == 3:\n",
    "        sample_img = sample_img.unsqueeze(0)\n",
    "    x = sample_img.to(DEVICE)\n",
    "\n",
    "    outputs = []\n",
    "    names = [\"Block 1 (Low Level - Edges)\", \"Block 2 (Mid Level - Textures)\", \"Block 3 (High Level - Parts)\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Step through your specific schema\n",
    "        x1 = model.block1(x)\n",
    "        outputs.append(x1.cpu())\n",
    "\n",
    "        x2 = model.block2(x1)\n",
    "        outputs.append(x2.cpu())\n",
    "\n",
    "        x3 = model.block3(x2)\n",
    "        outputs.append(x3.cpu())\n",
    "\n",
    "    for act, name in zip(outputs, names):\n",
    "        n_plot = 12  # Show first 12 filters per block for clarity\n",
    "        fig1, axes1 = plt.subplots(1, n_plot, figsize=(18, 2))\n",
    "        for j in range(n_plot):\n",
    "            f_map = act[0, j].numpy()\n",
    "            axes1[j].imshow(f_map, cmap='magma')\n",
    "            axes1[j].axis('off')\n",
    "        plt.suptitle(f\"Strategy 1: {name}\", fontsize=14)\n",
    "        plt.show()\n",
    "\n",
    "# --- RUN VISUALIZATIONS ---\n",
    "# Grab a sample image from your test set\n",
    "sample_img, _ = test_set[0]\n",
    "run_internal_visualizations(model, sample_img)"
   ],
   "id": "3bf4493e0e844e65"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:42:22.604417Z",
     "start_time": "2025-12-23T11:42:22.338589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def generate_visualizations(model, input_tensor, target_class=None):\n",
    "    model.eval()\n",
    "    target_layer = model.block3[3]\n",
    "\n",
    "    activations = None\n",
    "    gradients = None\n",
    "\n",
    "    def save_activations(module, input, output):\n",
    "        nonlocal activations\n",
    "        activations = output\n",
    "\n",
    "    def save_gradients(module, grad_input, grad_output):\n",
    "        nonlocal gradients\n",
    "        gradients = grad_output[0]\n",
    "\n",
    "    handle_a = target_layer.register_forward_hook(save_activations)\n",
    "    handle_g = target_layer.register_full_backward_hook(save_gradients)\n",
    "\n",
    "    # Prepare input: ensure it's on GPU and tracking gradients for the Saliency Map\n",
    "    input_tensor = input_tensor.unsqueeze(0).to(DEVICE).requires_grad_(True)\n",
    "    output = model(input_tensor)\n",
    "\n",
    "    if target_class is None:\n",
    "        target_class = output.argmax(dim=1).item()\n",
    "\n",
    "    model.zero_grad()\n",
    "    class_loss = output[0, target_class]\n",
    "    class_loss.backward()\n",
    "\n",
    "    # --- SALIENCY MAP (Gradients on original input) ---\n",
    "    # We take the absolute value of gradients and max across color channels\n",
    "    saliency, _ = torch.max(input_tensor.grad.data.abs(), dim=1)\n",
    "    saliency = saliency.squeeze().cpu().numpy()\n",
    "\n",
    "    # --- GRAD-CAM WEIGHTING LOGIC ---\n",
    "\n",
    "    # 1. Global Average Pooling of gradients (the \"Importance\" of each channel)\n",
    "    # This tells us how much the target class depends on each feature map concept\n",
    "    weights = torch.mean(gradients, dim=(2, 3), keepdim=True)\n",
    "\n",
    "    # 2. Weighted Sum: Each feature map is scaled by its importance weight\n",
    "    # This keeps 'useful' activations (e.g. wheels for cars) and suppresses noise (e.g. background trees)\n",
    "    cam = torch.sum(weights * activations, dim=1, keepdim=True)\n",
    "\n",
    "    # 3. ReLU: Only consider features that POSITIVELY contribute to the class score\n",
    "    cam = F.relu(cam)\n",
    "\n",
    "    # Upscale and normalize\n",
    "    cam = F.interpolate(cam, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "    cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-10)\n",
    "    heatmap = cam.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    handle_a.remove()\n",
    "    handle_g.remove()\n",
    "\n",
    "    return heatmap, saliency, target_class\n",
    "\n",
    "# --- EXECUTION & PLOTTING ---\n",
    "idx = 20\n",
    "img, label = test_set[idx]\n",
    "heatmap, saliency, pred = generate_visualizations(model, img)\n",
    "\n",
    "display_img = (img.permute(1, 2, 0).cpu().numpy())\n",
    "display_img = (display_img - display_img.min()) / (display_img.max() - display_img.min())\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "plt.subplot(1, 5, 1)\n",
    "plt.imshow(display_img)\n",
    "plt.title(f\"1. Original (Label: {label})\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Notice the noise level here compared to Grad-CAM\n",
    "plt.subplot(1, 5, 2)\n",
    "plt.imshow(saliency, cmap='hot')\n",
    "plt.title(\"2. Saliency (Input Grads)\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 5, 3)\n",
    "plt.imshow(heatmap, cmap='magma')\n",
    "plt.title(\"3. Grad-CAM Activation\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 5, 4)\n",
    "plt.imshow(heatmap, cmap='jet')\n",
    "plt.title(\"4. Grad-CAM Importance\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 5, 5)\n",
    "plt.imshow(display_img)\n",
    "plt.imshow(heatmap, cmap='jet', alpha=0.4)\n",
    "plt.title(f\"5. Decision RCA (Pred: {pred})\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ],
   "id": "c526b0fc85ec04f4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x500 with 5 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8a672c5b7b88bb4a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
