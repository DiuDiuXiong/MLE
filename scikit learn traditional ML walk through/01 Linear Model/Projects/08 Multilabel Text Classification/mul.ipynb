{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Multilabel Text Classification\n",
    "- Difficulty: Advanced\n",
    "- Project Purpose: Predict multiple tags (e.g., movie genres) from text. Stretch → compare One-vs-Rest Logistic Regression vs linear SVM.\n",
    "- Points Examined: Multi-label setting, OvR strategy, evaluation with F1-micro vs F1-macro.\n",
    "- Doc References: Scikit-learn multi-label docs, OvR/OvO strategies.\n",
    "- Why Useful: Expands classification intuition from binary → multi-class → multi-label, which is very real-world (tags, recommendations, incident categories)."
   ],
   "id": "4345e0c8d3c08b4f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Part 0 Data Download",
   "id": "8f4e29fda32c54cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T11:42:08.971301Z",
     "start_time": "2025-09-12T11:42:05.963084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "!curl -L -o ./multilabel-classification-dataset.zip https://www.kaggle.com/api/v1/datasets/download/shivanandmn/multilabel-classification-dataset"
   ],
   "id": "fa8dc818fa981e06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r\n",
      "100 11.4M  100 11.4M    0     0  4080k      0  0:00:02  0:00:02 --:--:-- 6420k\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T11:43:40.161344Z",
     "start_time": "2025-09-12T11:43:40.159368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "id": "b5af611f9e18fd3",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T11:44:03.504900Z",
     "start_time": "2025-09-12T11:44:03.150821Z"
    }
   },
   "cell_type": "code",
   "source": "!unzip ./multilabel-classification-dataset.zip",
   "id": "ba7c0216b5bb65c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./multilabel-classification-dataset.zip\r\n",
      "  inflating: sample_submission.csv   \r\n",
      "  inflating: test.csv                \r\n",
      "  inflating: train.csv               \r\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T11:44:37.357162Z",
     "start_time": "2025-09-12T11:44:37.085864Z"
    }
   },
   "cell_type": "code",
   "source": "train, test = pd.read_csv('./train.csv'), pd.read_csv('./test.csv')",
   "id": "e9087c16b315afda",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T11:45:58.496695Z",
     "start_time": "2025-09-12T11:45:58.491910Z"
    }
   },
   "cell_type": "code",
   "source": "train.tail()",
   "id": "b203b2ae14c50e22",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          ID                                              TITLE  \\\n",
       "20967  20968  Contemporary machine learning: a guide for pra...   \n",
       "20968  20969  Uniform diamond coatings on WC-Co hard alloy c...   \n",
       "20969  20970  Analysing Soccer Games with Clustering and Con...   \n",
       "20970  20971  On the Efficient Simulation of the Left-Tail o...   \n",
       "20971  20972   Why optional stopping is a problem for Bayesians   \n",
       "\n",
       "                                                ABSTRACT  Computer Science  \\\n",
       "20967    Machine learning is finding increasingly bro...                 1   \n",
       "20968    Polycrystalline diamond coatings have been g...                 0   \n",
       "20969    We present a new approach for identifying si...                 1   \n",
       "20970    The sum of Log-normal variates is encountere...                 0   \n",
       "20971    Recently, optional stopping has been a subje...                 0   \n",
       "\n",
       "       Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
       "20967        1            0           0                     0   \n",
       "20968        1            0           0                     0   \n",
       "20969        0            0           0                     0   \n",
       "20970        0            1           1                     0   \n",
       "20971        0            1           1                     0   \n",
       "\n",
       "       Quantitative Finance  \n",
       "20967                     0  \n",
       "20968                     0  \n",
       "20969                     0  \n",
       "20970                     0  \n",
       "20971                     0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20967</th>\n",
       "      <td>20968</td>\n",
       "      <td>Contemporary machine learning: a guide for pra...</td>\n",
       "      <td>Machine learning is finding increasingly bro...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20968</th>\n",
       "      <td>20969</td>\n",
       "      <td>Uniform diamond coatings on WC-Co hard alloy c...</td>\n",
       "      <td>Polycrystalline diamond coatings have been g...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20969</th>\n",
       "      <td>20970</td>\n",
       "      <td>Analysing Soccer Games with Clustering and Con...</td>\n",
       "      <td>We present a new approach for identifying si...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20970</th>\n",
       "      <td>20971</td>\n",
       "      <td>On the Efficient Simulation of the Left-Tail o...</td>\n",
       "      <td>The sum of Log-normal variates is encountere...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20971</th>\n",
       "      <td>20972</td>\n",
       "      <td>Why optional stopping is a problem for Bayesians</td>\n",
       "      <td>Recently, optional stopping has been a subje...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T11:48:44.341733Z",
     "start_time": "2025-09-12T11:48:44.339099Z"
    }
   },
   "cell_type": "code",
   "source": "test.shape",
   "id": "95bfcaaa78f4bba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8989, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T11:55:19.689678Z",
     "start_time": "2025-09-12T11:55:19.687193Z"
    }
   },
   "cell_type": "code",
   "source": "train.shape",
   "id": "7e6a3545c882130c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20972, 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T11:55:25.851005Z",
     "start_time": "2025-09-12T11:55:25.843140Z"
    }
   },
   "cell_type": "code",
   "source": "train.head()",
   "id": "c384b251dbcee2c5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   ID                                              TITLE  \\\n",
       "0   1        Reconstructing Subject-Specific Effect Maps   \n",
       "1   2                 Rotation Invariance Neural Network   \n",
       "2   3  Spherical polyharmonics and Poisson kernels fo...   \n",
       "3   4  A finite element approximation for the stochas...   \n",
       "4   5  Comparative study of Discrete Wavelet Transfor...   \n",
       "\n",
       "                                            ABSTRACT  Computer Science  \\\n",
       "0    Predictive models allow subject-specific inf...                 1   \n",
       "1    Rotation invariance and translation invarian...                 1   \n",
       "2    We introduce and develop the notion of spher...                 0   \n",
       "3    The stochastic Landau--Lifshitz--Gilbert (LL...                 0   \n",
       "4    Fourier-transform infra-red (FTIR) spectra o...                 1   \n",
       "\n",
       "   Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
       "0        0            0           0                     0   \n",
       "1        0            0           0                     0   \n",
       "2        0            1           0                     0   \n",
       "3        0            1           0                     0   \n",
       "4        0            0           1                     0   \n",
       "\n",
       "   Quantitative Finance  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
       "      <td>Predictive models allow subject-specific inf...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Rotation Invariance Neural Network</td>\n",
       "      <td>Rotation invariance and translation invarian...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
       "      <td>We introduce and develop the notion of spher...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A finite element approximation for the stochas...</td>\n",
       "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
       "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# Will only use train for both training and evaluation, as we don't have any way to verify against test set.",
   "id": "e2a0a40667273bd6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Part 1 Hypothesis and Planning",
   "id": "621c19bded87163a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T12:02:13.903097Z",
     "start_time": "2025-09-12T12:02:13.900267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label_cols = ['Computer Science', 'Physics', 'Mathematics', 'Statistics', 'Quantitative Biology', 'Quantitative Finance']\n",
    "featu_cols = ['TITLE', 'ABSTRACT']"
   ],
   "id": "390ad13a0516e645",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T12:03:52.565517Z",
     "start_time": "2025-09-12T12:03:52.559956Z"
    }
   },
   "cell_type": "code",
   "source": "train[label_cols].sum()",
   "id": "7c64f81884adec2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computer Science        8594\n",
       "Physics                 6013\n",
       "Mathematics             5618\n",
       "Statistics              5206\n",
       "Quantitative Biology     587\n",
       "Quantitative Finance     249\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T12:16:49.262353Z",
     "start_time": "2025-09-12T12:16:49.258489Z"
    }
   },
   "cell_type": "code",
   "source": "train[label_cols].isnull().sum()",
   "id": "aa1de4f96f53b3b8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computer Science        0\n",
       "Physics                 0\n",
       "Mathematics             0\n",
       "Statistics              0\n",
       "Quantitative Biology    0\n",
       "Quantitative Finance    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T13:03:13.040052Z",
     "start_time": "2025-09-12T13:03:13.038077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Since here the class is highly imbalance, we will need to also compute Macro F1 to ensure no specific group screw up\n",
    "# 2. We will compare OvR Classifier and MultiOutputClassifier, since in this case we won't need to have multiclass per column, each column is just a binary, we will use logistic regression to do classification here.\n",
    "# 3. The hypothesis is that OvR/MultiOutputClassifier will have similar performance against each other since they are doing similar stuff under the hood.\n",
    "# 4. Due to the imbalance of each class, although they are calculated separately, things like `Quantitative Biology/Finance` only have a very small amount of True samples, this might make the estimator very biased towards predict negative. So would imagine false negative be very serious issue. Will confusion matrix to have a check and if the issue is severe, will try to add a class balancer to the line or increase the weight of positive class."
   ],
   "id": "c65adbd3e94f54a4",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Part 3 Original Training (OvR) & MultiOutputClassifier",
   "id": "a7271c238077f49e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T13:25:52.006347Z",
     "start_time": "2025-09-12T13:25:51.999059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train[featu_cols], train[label_cols], test_size=0.2, random_state=42)"
   ],
   "id": "aeaf1226b7835755",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T13:37:20.187655Z",
     "start_time": "2025-09-12T13:37:20.181556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer"
   ],
   "id": "971dca2b67904156",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T13:40:59.611515Z",
     "start_time": "2025-09-12T13:40:59.608062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ovr = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"tfidf_tit\", TfidfVectorizer(), 'TITLE'),\n",
    "            (\"tfidf_abs\", TfidfVectorizer(), 'ABSTRACT'),\n",
    "        ]\n",
    "    ),\n",
    "    OneVsRestClassifier(LogisticRegression())\n",
    ")\n",
    "\n",
    "mul = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"tfidf_tit\", TfidfVectorizer(), 'TITLE'),\n",
    "            (\"tfidf_abs\", TfidfVectorizer(), 'ABSTRACT'),\n",
    "        ]\n",
    "    ),\n",
    "    MultiOutputClassifier(LogisticRegression())\n",
    ")"
   ],
   "id": "75829feaea3d6827",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T13:41:21.965126Z",
     "start_time": "2025-09-12T13:41:16.726337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ovr.fit(X_train, y_train)\n",
    "mul.fit(X_train, y_train)\n",
    "print(ovr.score(X_test, y_test))\n",
    "print(mul.score(X_test, y_test)) # score here will output rows that match all labels"
   ],
   "id": "9ad510ddf3e589b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6390941597139451\n",
      "0.6390941597139451\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T13:46:13.531726Z",
     "start_time": "2025-09-12T13:46:13.528994Z"
    }
   },
   "cell_type": "code",
   "source": "# Yea they are having same score because under the hood they are doing the same thing. The accuracy is > 0.5 which is great, means we are not doing random stuff, but the performance is pretty low, and the hypothesis is due to the imbalance class (i.e. too many 0s)",
   "id": "8ba71ce093e9dbad",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T13:55:15.165606Z",
     "start_time": "2025-09-12T13:55:15.162191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def print_performance_per_class(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    for i, col in enumerate(y.columns):\n",
    "        print(\"Performance for column {}:\".format(col))\n",
    "        print(classification_report(y[col], y_pred[:,i]))"
   ],
   "id": "d8528ef0e452b034",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T13:55:33.256764Z",
     "start_time": "2025-09-12T13:55:32.958989Z"
    }
   },
   "cell_type": "code",
   "source": "print_performance_per_class(mul, X_test, y_test)",
   "id": "d351df940ed9978b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for column Computer Science:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      2503\n",
      "           1       0.82      0.82      0.82      1692\n",
      "\n",
      "    accuracy                           0.86      4195\n",
      "   macro avg       0.85      0.85      0.85      4195\n",
      "weighted avg       0.86      0.86      0.86      4195\n",
      "\n",
      "Performance for column Physics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      2969\n",
      "           1       0.92      0.82      0.87      1226\n",
      "\n",
      "    accuracy                           0.93      4195\n",
      "   macro avg       0.93      0.90      0.91      4195\n",
      "weighted avg       0.93      0.93      0.93      4195\n",
      "\n",
      "Performance for column Mathematics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93      3045\n",
      "           1       0.88      0.74      0.80      1150\n",
      "\n",
      "    accuracy                           0.90      4195\n",
      "   macro avg       0.89      0.85      0.87      4195\n",
      "weighted avg       0.90      0.90      0.90      4195\n",
      "\n",
      "Performance for column Statistics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      3126\n",
      "           1       0.82      0.68      0.74      1069\n",
      "\n",
      "    accuracy                           0.88      4195\n",
      "   macro avg       0.86      0.81      0.83      4195\n",
      "weighted avg       0.88      0.88      0.88      4195\n",
      "\n",
      "Performance for column Quantitative Biology:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      4073\n",
      "           1       0.67      0.05      0.09       122\n",
      "\n",
      "    accuracy                           0.97      4195\n",
      "   macro avg       0.82      0.52      0.54      4195\n",
      "weighted avg       0.96      0.97      0.96      4195\n",
      "\n",
      "Performance for column Quantitative Finance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4150\n",
      "           1       1.00      0.13      0.24        45\n",
      "\n",
      "    accuracy                           0.99      4195\n",
      "   macro avg       1.00      0.57      0.62      4195\n",
      "weighted avg       0.99      0.99      0.99      4195\n",
      "\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T13:50:54.816724Z",
     "start_time": "2025-09-12T13:50:54.812353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We see that for precision its always fine for both 0 and 1, but for recall, the results is not that good as number of positive values drop\n",
    "# We care more about Class 1 recall, because it is the minority. While at sample size 8k+, this seems no difference. However when  number starts to drop, we see that the performance already drop, for example for stats that the number is 5206, the Class 1 Recall already come to 0.68, and for the last two, things get to 0.05 and 0.13 which is basically ignore the class unless super confident."
   ],
   "id": "62e4687be71c1584",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20257    1\n",
       "482      0\n",
       "4189     1\n",
       "9838     0\n",
       "16591    1\n",
       "        ..\n",
       "14740    0\n",
       "3755     0\n",
       "10684    0\n",
       "16274    0\n",
       "14452    1\n",
       "Name: Computer Science, Length: 4195, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Part 4 Dealing with imbalanced class",
   "id": "69d1774b11a52913"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T14:17:51.817665Z",
     "start_time": "2025-09-12T14:17:51.810686Z"
    }
   },
   "cell_type": "code",
   "source": "y_train[y_train.sum(axis=1) == 0] # Okay so there's no pure 0 line",
   "id": "96ddbc2b8a67a633",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Computer Science, Physics, Mathematics, Statistics, Quantitative Biology, Quantitative Finance]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T15:15:47.444797Z",
     "start_time": "2025-09-12T15:15:47.434416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# first try balanced class weight, also try ngram2\n",
    "ovr = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"tfidf_tit\", TfidfVectorizer(), 'TITLE'),\n",
    "            (\"tfidf_abs\", TfidfVectorizer(), 'ABSTRACT'),\n",
    "        ]\n",
    "    ),\n",
    "    OneVsRestClassifier(LogisticRegression(class_weight='balanced'))\n",
    ")\n",
    "\n",
    "mul = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"tfidf_tit\", TfidfVectorizer(), 'TITLE'),\n",
    "            (\"tfidf_abs\", TfidfVectorizer(), 'ABSTRACT'),\n",
    "        ]\n",
    "    ),\n",
    "    MultiOutputClassifier(LogisticRegression(class_weight='balanced'))\n",
    ")\n",
    "\n",
    "ovr2 = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"tfidf_tit\", TfidfVectorizer(ngram_range=(2, 2)), 'TITLE'),\n",
    "            (\"tfidf_abs\", TfidfVectorizer(ngram_range=(2, 2)), 'ABSTRACT'),\n",
    "        ]\n",
    "    ),\n",
    "    OneVsRestClassifier(LogisticRegression(class_weight='balanced'))\n",
    ")\n",
    "\n",
    "mul2 = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"tfidf_tit\", TfidfVectorizer(ngram_range=(2, 2)), 'TITLE'),\n",
    "            (\"tfidf_abs\", TfidfVectorizer(ngram_range=(2, 2)), 'ABSTRACT'),\n",
    "        ]\n",
    "    ),\n",
    "    MultiOutputClassifier(LogisticRegression(class_weight='balanced'))\n",
    ")"
   ],
   "id": "1d664e6cb41dcca4",
   "outputs": [],
   "execution_count": 131
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T15:16:28.278611Z",
     "start_time": "2025-09-12T15:15:57.675379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ovr.fit(X_train, y_train)\n",
    "mul.fit(X_train, y_train)\n",
    "ovr2.fit(X_train, y_train)\n",
    "mul2.fit(X_train, y_train)\n",
    "print(ovr.score(X_test, y_test))\n",
    "print(mul.score(X_test, y_test)) # well a bit better?\n",
    "print(mul2.score(X_test, y_test))\n",
    "print(ovr2.score(X_test, y_test))"
   ],
   "id": "447c680f50e87cc8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6407628128724672\n",
      "0.6407628128724672\n",
      "0.6166865315852205\n",
      "0.6166865315852205\n"
     ]
    }
   ],
   "execution_count": 132
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T14:24:18.528139Z",
     "start_time": "2025-09-12T14:24:18.224829Z"
    }
   },
   "cell_type": "code",
   "source": "print_performance_per_class(mul, X_test, y_test)",
   "id": "8d505e4e4738f383",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for column Computer Science:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.88      2503\n",
      "           1       0.80      0.87      0.84      1692\n",
      "\n",
      "    accuracy                           0.86      4195\n",
      "   macro avg       0.86      0.86      0.86      4195\n",
      "weighted avg       0.87      0.86      0.86      4195\n",
      "\n",
      "Performance for column Physics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      2969\n",
      "           1       0.87      0.87      0.87      1226\n",
      "\n",
      "    accuracy                           0.92      4195\n",
      "   macro avg       0.91      0.91      0.91      4195\n",
      "weighted avg       0.92      0.92      0.92      4195\n",
      "\n",
      "Performance for column Mathematics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93      3045\n",
      "           1       0.79      0.84      0.81      1150\n",
      "\n",
      "    accuracy                           0.89      4195\n",
      "   macro avg       0.86      0.88      0.87      4195\n",
      "weighted avg       0.90      0.89      0.90      4195\n",
      "\n",
      "Performance for column Statistics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92      3126\n",
      "           1       0.74      0.85      0.79      1069\n",
      "\n",
      "    accuracy                           0.89      4195\n",
      "   macro avg       0.84      0.87      0.86      4195\n",
      "weighted avg       0.89      0.89      0.89      4195\n",
      "\n",
      "Performance for column Quantitative Biology:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      4073\n",
      "           1       0.49      0.61      0.54       122\n",
      "\n",
      "    accuracy                           0.97      4195\n",
      "   macro avg       0.74      0.79      0.76      4195\n",
      "weighted avg       0.97      0.97      0.97      4195\n",
      "\n",
      "Performance for column Quantitative Finance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4150\n",
      "           1       0.76      0.69      0.72        45\n",
      "\n",
      "    accuracy                           0.99      4195\n",
      "   macro avg       0.88      0.84      0.86      4195\n",
      "weighted avg       0.99      0.99      0.99      4195\n",
      "\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T14:39:01.224824Z",
     "start_time": "2025-09-12T14:39:01.222820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Quantitative Biology -> 1      0.67->0.49, 0.05->0.61\n",
    "# Quantitative Finance -> 1      1.00->0.76, 0.57->0.69\n",
    "# The trade off here is great, although we are miss classifying some, we do get some improvement especially for finance."
   ],
   "id": "e1256a35aa5305ae",
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T14:44:03.004380Z",
     "start_time": "2025-09-12T14:44:03.002163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# However, the difference for the mini class here is still huge against the major class. So here we will do separate training for Quantitative-Features and others. The strategy is:\n",
    "#  - Model 1: Predict features other than Quantitative*\n",
    "#  - Model 2:\n",
    "#    - Sub Model 1: Predict if it is Quantitative or not\n",
    "#    - Sub Model 2: Predict if it is Biology or Finance"
   ],
   "id": "2ee21aabe49693e0",
   "outputs": [],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T14:44:25.482666Z",
     "start_time": "2025-09-12T14:44:25.480971Z"
    }
   },
   "cell_type": "code",
   "source": "# Since Model 1 is just a subset of above, will skip and will only focus on Model 2.",
   "id": "56f36807dd224bc3",
   "outputs": [],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T14:49:16.928777Z",
     "start_time": "2025-09-12T14:49:16.925867Z"
    }
   },
   "cell_type": "code",
   "source": "train_cpy = train.copy()\n",
   "id": "9c35332228485799",
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T14:50:14.872898Z",
     "start_time": "2025-09-12T14:50:14.870559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "featu_cols = ['TITLE', 'ABSTRACT']\n",
    "label_cols = ['Quantitative Biology', 'Quantitative Finance']"
   ],
   "id": "5ebea7bd72661de9",
   "outputs": [],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T14:50:26.535704Z",
     "start_time": "2025-09-12T14:50:26.530684Z"
    }
   },
   "cell_type": "code",
   "source": "train_cpy.head()",
   "id": "1cbc1b0697c086bd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   ID  \\\n",
       "0   1   \n",
       "1   2   \n",
       "2   3   \n",
       "3   4   \n",
       "4   5   \n",
       "\n",
       "                                                                                                                                            TITLE  \\\n",
       "0                                                                                                     Reconstructing Subject-Specific Effect Maps   \n",
       "1                                                                                                              Rotation Invariance Neural Network   \n",
       "2                                                                          Spherical polyharmonics and Poisson kernels for polyharmonic functions   \n",
       "3                                                     A finite element approximation for the stochastic Maxwell--Landau--Lifshitz--Gilbert system   \n",
       "4  Comparative study of Discrete Wavelet Transforms and Wavelet Tensor Train decomposition to feature extraction of FTIR data of medicinal plants   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ABSTRACT  \\\n",
       "0    Predictive models allow subject-specific inference when analyzing disease\\nrelated alterations in neuroimaging data. Given a subject's data, inference can\\nbe made at two levels: global, i.e. identifiying condition presence for the\\nsubject, and local, i.e. detecting condition effect on each individual\\nmeasurement extracted from the subject's data. While global inference is widely\\nused, local inference, which can be used to form subject-specific effect maps,\\nis rarely used because existing models often yield noisy detections composed of\\ndispersed isolated islands. In this article, we propose a reconstruction\\nmethod, named RSM, to improve subject-specific detections of predictive\\nmodeling approaches and in particular, binary classifiers. RSM specifically\\naims to reduce noise due to sampling error associated with using a finite\\nsample of examples to train classifiers. The proposed method is a wrapper-type\\nalgorithm that can be used with different binary classifiers in a diagnostic\\nmanner, i.e. without information on condition presence. Reconstruction is posed\\nas a Maximum-A-Posteriori problem with a prior model whose parameters are\\nestimated from training data in a classifier-specific fashion. Experimental\\nevaluation is performed on synthetically generated data and data from the\\nAlzheimer's Disease Neuroimaging Initiative (ADNI) database. Results on\\nsynthetic data demonstrate that using RSM yields higher detection accuracy\\ncompared to using models directly or with bootstrap averaging. Analyses on the\\nADNI dataset show that RSM can also improve correlation between\\nsubject-specific detections in cortical thickness data and non-imaging markers\\nof Alzheimer's Disease (AD), such as the Mini Mental State Examination Score\\nand Cerebrospinal Fluid amyloid-$\\beta$ levels. Further reliability studies on\\nthe longitudinal ADNI dataset show improvement on detection reliability when\\nRSM is used.\\n   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Rotation invariance and translation invariance have great values in image\\nrecognition tasks. In this paper, we bring a new architecture in convolutional\\nneural network (CNN) named cyclic convolutional layer to achieve rotation\\ninvariance in 2-D symbol recognition. We can also get the position and\\norientation of the 2-D symbol by the network to achieve detection purpose for\\nmultiple non-overlap target. Last but not least, this architecture can achieve\\none-shot learning in some cases using those invariance.\\n   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 We introduce and develop the notion of spherical polyharmonics, which are a\\nnatural generalisation of spherical harmonics. In particular we study the\\ntheory of zonal polyharmonics, which allows us, analogously to zonal harmonics,\\nto construct Poisson kernels for polyharmonic functions on the union of rotated\\nballs. We find the representation of Poisson kernels and zonal polyharmonics in\\nterms of the Gegenbauer polynomials. We show the connection between the\\nclassical Poisson kernel for harmonic functions on the ball, Poisson kernels\\nfor polyharmonic functions on the union of rotated balls, and the Cauchy-Hua\\nkernel for holomorphic functions on the Lie ball.\\n   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            The stochastic Landau--Lifshitz--Gilbert (LLG) equation coupled with the\\nMaxwell equations (the so called stochastic MLLG system) describes the creation\\nof domain walls and vortices (fundamental objects for the novel nanostructured\\nmagnetic memories). We first reformulate the stochastic LLG equation into an\\nequation with time-differentiable solutions. We then propose a convergent\\n$\\theta$-linear scheme to approximate the solutions of the reformulated system.\\nAs a consequence, we prove convergence of the approximate solutions, with no or\\nminor conditions on time and space steps (depending on the value of $\\theta$).\\nHence, we prove the existence of weak martingale solutions of the stochastic\\nMLLG system. Numerical results are presented to show applicability of the\\nmethod.\\n   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Fourier-transform infra-red (FTIR) spectra of samples from 7 plant species\\nwere used to explore the influence of preprocessing and feature extraction on\\nefficiency of machine learning algorithms. Wavelet Tensor Train (WTT) and\\nDiscrete Wavelet Transforms (DWT) were compared as feature extraction\\ntechniques for FTIR data of medicinal plants. Various combinations of signal\\nprocessing steps showed different behavior when applied to classification and\\nclustering tasks. Best results for WTT and DWT found through grid search were\\nsimilar, significantly improving quality of clustering as well as\\nclassification accuracy for tuned logistic regression in comparison to original\\nspectra. Unlike DWT, WTT has only one parameter to be tuned (rank), making it a\\nmore versatile and easier to use as a data processing tool in various signal\\nprocessing applications.\\n   \n",
       "\n",
       "   Computer Science  Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
       "0                 1        0            0           0                     0   \n",
       "1                 1        0            0           0                     0   \n",
       "2                 0        0            1           0                     0   \n",
       "3                 0        0            1           0                     0   \n",
       "4                 1        0            0           1                     0   \n",
       "\n",
       "   Quantitative Finance  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
       "      <td>Predictive models allow subject-specific inference when analyzing disease\\nrelated alterations in neuroimaging data. Given a subject's data, inference can\\nbe made at two levels: global, i.e. identifiying condition presence for the\\nsubject, and local, i.e. detecting condition effect on each individual\\nmeasurement extracted from the subject's data. While global inference is widely\\nused, local inference, which can be used to form subject-specific effect maps,\\nis rarely used because existing models often yield noisy detections composed of\\ndispersed isolated islands. In this article, we propose a reconstruction\\nmethod, named RSM, to improve subject-specific detections of predictive\\nmodeling approaches and in particular, binary classifiers. RSM specifically\\naims to reduce noise due to sampling error associated with using a finite\\nsample of examples to train classifiers. The proposed method is a wrapper-type\\nalgorithm that can be used with different binary classifiers in a diagnostic\\nmanner, i.e. without information on condition presence. Reconstruction is posed\\nas a Maximum-A-Posteriori problem with a prior model whose parameters are\\nestimated from training data in a classifier-specific fashion. Experimental\\nevaluation is performed on synthetically generated data and data from the\\nAlzheimer's Disease Neuroimaging Initiative (ADNI) database. Results on\\nsynthetic data demonstrate that using RSM yields higher detection accuracy\\ncompared to using models directly or with bootstrap averaging. Analyses on the\\nADNI dataset show that RSM can also improve correlation between\\nsubject-specific detections in cortical thickness data and non-imaging markers\\nof Alzheimer's Disease (AD), such as the Mini Mental State Examination Score\\nand Cerebrospinal Fluid amyloid-$\\beta$ levels. Further reliability studies on\\nthe longitudinal ADNI dataset show improvement on detection reliability when\\nRSM is used.\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Rotation Invariance Neural Network</td>\n",
       "      <td>Rotation invariance and translation invariance have great values in image\\nrecognition tasks. In this paper, we bring a new architecture in convolutional\\nneural network (CNN) named cyclic convolutional layer to achieve rotation\\ninvariance in 2-D symbol recognition. We can also get the position and\\norientation of the 2-D symbol by the network to achieve detection purpose for\\nmultiple non-overlap target. Last but not least, this architecture can achieve\\none-shot learning in some cases using those invariance.\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Spherical polyharmonics and Poisson kernels for polyharmonic functions</td>\n",
       "      <td>We introduce and develop the notion of spherical polyharmonics, which are a\\nnatural generalisation of spherical harmonics. In particular we study the\\ntheory of zonal polyharmonics, which allows us, analogously to zonal harmonics,\\nto construct Poisson kernels for polyharmonic functions on the union of rotated\\nballs. We find the representation of Poisson kernels and zonal polyharmonics in\\nterms of the Gegenbauer polynomials. We show the connection between the\\nclassical Poisson kernel for harmonic functions on the ball, Poisson kernels\\nfor polyharmonic functions on the union of rotated balls, and the Cauchy-Hua\\nkernel for holomorphic functions on the Lie ball.\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A finite element approximation for the stochastic Maxwell--Landau--Lifshitz--Gilbert system</td>\n",
       "      <td>The stochastic Landau--Lifshitz--Gilbert (LLG) equation coupled with the\\nMaxwell equations (the so called stochastic MLLG system) describes the creation\\nof domain walls and vortices (fundamental objects for the novel nanostructured\\nmagnetic memories). We first reformulate the stochastic LLG equation into an\\nequation with time-differentiable solutions. We then propose a convergent\\n$\\theta$-linear scheme to approximate the solutions of the reformulated system.\\nAs a consequence, we prove convergence of the approximate solutions, with no or\\nminor conditions on time and space steps (depending on the value of $\\theta$).\\nHence, we prove the existence of weak martingale solutions of the stochastic\\nMLLG system. Numerical results are presented to show applicability of the\\nmethod.\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Comparative study of Discrete Wavelet Transforms and Wavelet Tensor Train decomposition to feature extraction of FTIR data of medicinal plants</td>\n",
       "      <td>Fourier-transform infra-red (FTIR) spectra of samples from 7 plant species\\nwere used to explore the influence of preprocessing and feature extraction on\\nefficiency of machine learning algorithms. Wavelet Tensor Train (WTT) and\\nDiscrete Wavelet Transforms (DWT) were compared as feature extraction\\ntechniques for FTIR data of medicinal plants. Various combinations of signal\\nprocessing steps showed different behavior when applied to classification and\\nclustering tasks. Best results for WTT and DWT found through grid search were\\nsimilar, significantly improving quality of clustering as well as\\nclassification accuracy for tuned logistic regression in comparison to original\\nspectra. Unlike DWT, WTT has only one parameter to be tuned (rank), making it a\\nmore versatile and easier to use as a data processing tool in various signal\\nprocessing applications.\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "(((train_cpy['Quantitative Biology'] + train_cpy['Quantitative Finance']) >= 1).astype(int)).sum() # okay not too bad, we still got 832..",
   "id": "41b4fbe78ff18c87"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T15:26:07.253775Z",
     "start_time": "2025-09-12T15:26:07.249278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_cpy['Quantitative'] = ((train_cpy['Quantitative Biology'] + train_cpy['Quantitative Finance']) >= 1).astype(int) # features used for is Quantitative/Is not Quantitative\n",
    "train_cpy['Finance'] = train_cpy['Quantitative Finance'] # Finance/Biology Test\n",
    "train_cpy['Biology'] = np.zeros(len(train_cpy)) #Finance/Biology Test"
   ],
   "id": "21347ae368e09737",
   "outputs": [],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T15:27:20.011019Z",
     "start_time": "2025-09-12T15:27:20.001330Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, X_test, y_train, y_test = train_test_split(train_cpy[featu_cols], train_cpy['Quantitative'], test_size=0.2, random_state=42, stratify=train_cpy['Quantitative'])",
   "id": "eff3ac28da4064f",
   "outputs": [],
   "execution_count": 135
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T15:27:22.099125Z",
     "start_time": "2025-09-12T15:27:20.351282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lets first train the model of Quantitative or not with balanced class, if things are not that accurate, we may consider using up-sampling\n",
    "quantitative_check = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"tfidf_ABS\", TfidfVectorizer(sublinear_tf=True), 'ABSTRACT'),\n",
    "            (\"tfidf_TITLE\", TfidfVectorizer(sublinear_tf=True), 'TITLE'),\n",
    "        ]\n",
    "    ),\n",
    "    LogisticRegression(class_weight='balanced')\n",
    ")\n",
    "quantitative_check.fit(X_train, y_train)\n",
    "quantitative_check.score(X_test, y_test)"
   ],
   "id": "6c436c95cdf9d260",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9594755661501788"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 136
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T15:27:50.438661Z",
     "start_time": "2025-09-12T15:27:50.145782Z"
    }
   },
   "cell_type": "code",
   "source": "print(classification_report(y_test, quantitative_check.predict(X_test))) # :( still bad recall for class 1, lets do up sampling",
   "id": "f7bae76994b23ed7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      4029\n",
      "           1       0.49      0.61      0.54       166\n",
      "\n",
      "    accuracy                           0.96      4195\n",
      "   macro avg       0.74      0.79      0.76      4195\n",
      "weighted avg       0.96      0.96      0.96      4195\n",
      "\n"
     ]
    }
   ],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T15:31:49.392395Z",
     "start_time": "2025-09-12T15:31:49.387526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.utils import resample\n",
    "X_train_maj, X_train_min = X_train[y_train == 0], X_train[y_train == 1]\n",
    "y_train_maj, y_train_min = y_train[y_train == 0], y_train[y_train == 1]\n"
   ],
   "id": "8ef18c99cc23657a",
   "outputs": [],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T15:35:05.688216Z",
     "start_time": "2025-09-12T15:35:05.683967Z"
    }
   },
   "cell_type": "code",
   "source": "X_train_min, y_train_min = resample(X_train_min, y_train_min, random_state=42, n_samples=len(X_train_maj), replace=True)",
   "id": "e02ab71a3870957c",
   "outputs": [],
   "execution_count": 146
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T15:35:06.583087Z",
     "start_time": "2025-09-12T15:35:06.580756Z"
    }
   },
   "cell_type": "code",
   "source": "print(X_train_min.shape, y_train_min.shape)",
   "id": "3182a9a3f0316d89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16111, 2) (16111,)\n"
     ]
    }
   ],
   "execution_count": 147
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T15:35:50.571925Z",
     "start_time": "2025-09-12T15:35:50.568905Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, y_train = pd.concat([X_train_min, X_train_maj]), pd.concat([y_train_min, y_train_maj])",
   "id": "802a3a0ae3d10dfc",
   "outputs": [],
   "execution_count": 148
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T15:41:04.148929Z",
     "start_time": "2025-09-12T15:40:58.688778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "quantitative_check = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"tfidf_ABS\", TfidfVectorizer(sublinear_tf=True), 'ABSTRACT'),\n",
    "            (\"tfidf_TITLE\", TfidfVectorizer(sublinear_tf=True), 'TITLE'),\n",
    "        ]\n",
    "    ),\n",
    "    LogisticRegression()\n",
    ")\n",
    "quantitative_check.fit(X_train, y_train)\n",
    "quantitative_check.score(X_test, y_test)\n",
    "quantitative_check.fit(X_train, y_train)\n",
    "quantitative_check.score(X_test, y_test)"
   ],
   "id": "3d4be70ac557017c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9611442193087009"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 154
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T15:41:04.483339Z",
     "start_time": "2025-09-12T15:41:04.215267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(classification_report(y_test, quantitative_check.predict(X_test))) # Seems like even after this, the 1 class still suffer from great issue of insufficient data, although we are not sure why after up-sampling it is still very biased towards 0? But at this stage, it is safe to say that we need more data.\n",
    "# But interesting to see why precision/recall can stay high for class 0 while 1 is still bit biased? Like if I trained stuff on an even dataset, then precision and recall for 0 should also drop?"
   ],
   "id": "f2ca7ee9a01eeefd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      4029\n",
      "           1       0.51      0.57      0.54       166\n",
      "\n",
      "    accuracy                           0.96      4195\n",
      "   macro avg       0.75      0.77      0.76      4195\n",
      "weighted avg       0.96      0.96      0.96      4195\n",
      "\n"
     ]
    }
   ],
   "execution_count": 155
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T15:47:53.854672Z",
     "start_time": "2025-09-12T15:47:53.851093Z"
    }
   },
   "cell_type": "code",
   "source": "y_train.value_counts()",
   "id": "8d9b651840638b0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quantitative\n",
       "1    16111\n",
       "0    16111\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 156
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# GPT's review below",
   "id": "1a09ca2cfcdfa6e9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "TL;DR feedback\n",
    "\n",
    "- .score in your multilabel setup = subset accuracy (strict). Keep using per-label metrics (micro/macro F1, Hamming loss, Jaccard).\n",
    "- Your ColumnTransformer + TfidfVectorizer approach is good. For text-only data, consider concatenating title+abstract or keep both but weight title higher.\n",
    "- For rare labels (Quant Bio / Quant Finance), fix recall via per-label threshold tuning, class_weight='balanced', and possibly ClassifierChain. (I.E. after the model, check threshold that can give best F1)\n",
    "- Prefer LogisticRegression(solver='saga', max_iter=2000) for large sparse TF-IDF; try L1 / elastic-net to drop junk features.\n",
    "- Add PR-AUC per label; optimize thresholds by F1@best-threshold per label."
   ],
   "id": "3a1934f175e173a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T16:22:25.609397Z",
     "start_time": "2025-09-12T16:22:25.607661Z"
    }
   },
   "cell_type": "code",
   "source": "# https://stackoverflow.com/questions/38640109/logistic-regression-python-solvers-definitions",
   "id": "d778823273ab4d38",
   "outputs": [],
   "execution_count": 161
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9b7d090bec014dac"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
